{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ² Tabular Data Generation with Diffusion Models\n",
        "\n",
        "**Generate High-Quality Synthetic Tabular Data**\n",
        "\n",
        "This notebook demonstrates how to generate synthetic tabular data using diffusion models with explainability.\n",
        "\n",
        "## ðŸ“‹ What You'll Learn:\n",
        "1. âœ… Load and explore tabular datasets\n",
        "2. âœ… Train a specialized tabular diffusion model\n",
        "3. âœ… Generate synthetic data that matches real distributions\n",
        "4. âœ… Visualize and compare real vs synthetic data\n",
        "5. âœ… Evaluate data quality\n",
        "\n",
        "## ðŸŽ¯ Use Cases:\n",
        "- **Privacy-preserving data sharing** (medical records, financial data)\n",
        "- **Data augmentation** for imbalanced datasets\n",
        "- **Testing and development** with realistic synthetic data\n",
        "- **Research** without access to real sensitive data\n",
        "\n",
        "---\n",
        "\n",
        "**âš ï¸ Note**: This notebook works best with GPU but can run on CPU (slower)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸš€ GOOGLE COLAB SETUP - Run this cell first if using Colab!\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Check if running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"ðŸŒ Running in Google Colab\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"ðŸ’» Running locally\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ðŸ”§ Setting up environment for Google Colab...\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Remove old clone if exists\n",
        "    if os.path.exists('/content/Data-generation'):\n",
        "        print(\"\\nðŸ—‘ï¸  Removing old clone...\")\n",
        "        subprocess.run(['rm', '-rf', '/content/Data-generation'], check=True)\n",
        "    \n",
        "    # Clone repository\n",
        "    print(\"\\nðŸ“¥ Cloning repository...\")\n",
        "    subprocess.run(['git', 'clone', 'https://github.com/ayansh1729/Data-generation.git'], \n",
        "                   cwd='/content', check=True)\n",
        "    print(\"   âœ… Repository cloned\")\n",
        "    \n",
        "    # Change to project directory\n",
        "    os.chdir('/content/Data-generation')\n",
        "    print(f\"   ðŸ“‚ Working directory: {os.getcwd()}\")\n",
        "    \n",
        "    # Install dependencies\n",
        "    print(\"\\nðŸ“¦ Installing dependencies...\")\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-r', 'requirements.txt'], check=True)\n",
        "    print(\"   âœ… Dependencies installed\")\n",
        "    \n",
        "    # Install package\n",
        "    print(\"\\nâš™ï¸  Installing project...\")\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-e', '.'], check=True)\n",
        "    print(\"   âœ… Project installed\")\n",
        "    \n",
        "    # Add to path\n",
        "    sys.path.insert(0, '/content/Data-generation')\n",
        "    \n",
        "    # Check GPU\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "        print(f\"\\nðŸŽ® GPU Available: {gpu_name}\")\n",
        "        print(f\"   Memory: {gpu_memory:.1f} GB\")\n",
        "    else:\n",
        "        print(\"\\nâš ï¸  No GPU detected. Training will be slower.\")\n",
        "        print(\"   ðŸ’¡ Enable GPU: Runtime â†’ Change runtime type â†’ GPU\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"âœ… Setup complete!\")\n",
        "    print(\"=\"*70)\n",
        "else:\n",
        "    print(\"â„¹ï¸  Not in Colab - using local environment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer, load_wine, load_diabetes\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Project imports\n",
        "from src.models.tabular_diffusion import TabularDiffusionModel\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ðŸ”§ Using device: {device}\")\n",
        "print(f\"ðŸ PyTorch version: {torch.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Load and Explore Dataset\n",
        "\n",
        "We'll use the **Breast Cancer Wisconsin** dataset - a classic medical dataset with 30 features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "print(f\"ðŸ“Š Dataset: Breast Cancer Wisconsin\")\n",
        "print(f\"   Samples: {X.shape[0]}\")\n",
        "print(f\"   Features: {X.shape[1]}\")\n",
        "print(f\"   Classes: {len(np.unique(y))} (Malignant: {(y==0).sum()}, Benign: {(y==1).sum()})\")\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "# Display first few rows\n",
        "print(\"\\nðŸ“‹ First few samples:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary\n",
        "print(\"ðŸ“ˆ Statistical Summary:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize feature distributions\n",
        "fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(9):\n",
        "    axes[i].hist(X[:, i], bins=40, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "    axes[i].set_title(f\"{feature_names[i]}\", fontsize=11, fontweight='bold')\n",
        "    axes[i].set_xlabel('Value', fontsize=9)\n",
        "    axes[i].set_ylabel('Frequency', fontsize=9)\n",
        "    axes[i].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('ðŸ“Š Feature Distributions (Real Data)', y=1.002, fontsize=15, fontweight='bold')\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… First 9 features visualized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PCA Visualization\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', \n",
        "                     alpha=0.6, edgecolors='k', s=50)\n",
        "plt.colorbar(scatter, label='Class (0=Malignant, 1=Benign)')\n",
        "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)', fontsize=12)\n",
        "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)', fontsize=12)\n",
        "plt.title('ðŸ” Real Data - PCA Visualization', fontweight='bold', fontsize=14)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"âœ… PCA explains {(pca.explained_variance_ratio_[0] + pca.explained_variance_ratio_[1])*100:.1f}% of variance\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Prepare Data for Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Create simple dataset class\n",
        "class TabularDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = torch.FloatTensor(data)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = TabularDataset(X_normalized)\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "print(f\"âœ… Data prepared\")\n",
        "print(f\"   Dataset size: {len(dataset)}\")\n",
        "print(f\"   Batch size: 64\")\n",
        "print(f\"   Number of batches: {len(dataloader)}\")\n",
        "print(f\"   Normalized range: [{X_normalized.min():.2f}, {X_normalized.max():.2f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ—ï¸ Create Tabular Diffusion Model\n",
        "\n",
        "We use a specialized MLP-based architecture (not U-Net) optimized for tabular data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Tabular Diffusion Model\n",
        "input_dim = X.shape[1]\n",
        "\n",
        "model = TabularDiffusionModel(\n",
        "    input_dim=input_dim,\n",
        "    hidden_dims=(256, 512, 512, 256),\n",
        "    time_emb_dim=128,\n",
        "    dropout=0.1,\n",
        "    use_batch_norm=True\n",
        ").to(device)\n",
        "\n",
        "# Create DDPM wrapper for training and sampling\n",
        "class TabularDDPM(nn.Module):\n",
        "    def __init__(self, model, timesteps=1000):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.timesteps = timesteps\n",
        "        \n",
        "        # Cosine noise schedule (better for tabular data)\n",
        "        steps = timesteps + 1\n",
        "        x = torch.linspace(0, timesteps, steps)\n",
        "        alphas_cumprod = torch.cos(((x / timesteps) + 0.008) / 1.008 * torch.pi * 0.5) ** 2\n",
        "        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "        betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "        betas = torch.clip(betas, 0.0001, 0.9999)\n",
        "        \n",
        "        alphas = 1.0 - betas\n",
        "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
        "        \n",
        "        self.register_buffer('betas', betas)\n",
        "        self.register_buffer('alphas', alphas)\n",
        "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
        "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
        "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1.0 - alphas_cumprod))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"Training forward pass.\"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "        device = x.device\n",
        "        \n",
        "        # Random timesteps\n",
        "        t = torch.randint(0, self.timesteps, (batch_size,), device=device)\n",
        "        noise = torch.randn_like(x)\n",
        "        \n",
        "        # Add noise to data\n",
        "        sqrt_alpha = self.sqrt_alphas_cumprod[t].unsqueeze(-1)\n",
        "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod[t].unsqueeze(-1)\n",
        "        x_noisy = sqrt_alpha * x + sqrt_one_minus_alpha * noise\n",
        "        \n",
        "        # Predict noise\n",
        "        predicted = self.model(x_noisy, t)\n",
        "        loss = nn.functional.mse_loss(predicted, noise)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    @torch.no_grad()\n",
        "    def sample(self, num_samples, dim):\n",
        "        \"\"\"Generate samples via reverse diffusion.\"\"\"\n",
        "        device = next(self.parameters()).device\n",
        "        x = torch.randn(num_samples, dim, device=device)\n",
        "        \n",
        "        for t in tqdm(reversed(range(self.timesteps)), desc='ðŸŽ² Generating', total=self.timesteps):\n",
        "            t_batch = torch.full((num_samples,), t, device=device, dtype=torch.long)\n",
        "            predicted_noise = self.model(x, t_batch)\n",
        "            \n",
        "            alpha_t = self.alphas[t]\n",
        "            alpha_cumprod_t = self.alphas_cumprod[t]\n",
        "            beta_t = self.betas[t]\n",
        "            \n",
        "            if t > 0:\n",
        "                noise = torch.randn_like(x)\n",
        "            else:\n",
        "                noise = torch.zeros_like(x)\n",
        "            \n",
        "            x = (x - beta_t / torch.sqrt(1 - alpha_cumprod_t) * predicted_noise) / torch.sqrt(alpha_t)\n",
        "            x = x + torch.sqrt(beta_t) * noise\n",
        "        \n",
        "        return x\n",
        "\n",
        "ddpm = TabularDDPM(model, timesteps=1000).to(device)\n",
        "\n",
        "num_params = sum(p.numel() for p in ddpm.parameters())\n",
        "print(f\"\\\\nâœ… Model created successfully!\")\n",
        "print(f\"   Input dimension: {input_dim}\")\n",
        "print(f\"   Hidden dimensions: (256, 512, 512, 256)\")\n",
        "print(f\"   Time embedding: 128\")\n",
        "print(f\"   Total parameters: {num_params:,}\")\n",
        "print(f\"   Timesteps: 1000\")\n",
        "print(f\"   Noise schedule: Cosine\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
