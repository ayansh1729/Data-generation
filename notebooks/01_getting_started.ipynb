{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŒ Run in Google Colab\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ayansh1729/Data-generation/blob/main/notebooks/01_getting_started.ipynb)\n",
        "\n",
        "**Running in Google Colab?** Execute the cell below to set up everything automatically!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸš€ GOOGLE COLAB SETUP - Run this cell first if using Colab!\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Check if running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"ðŸŒ Running in Google Colab\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"ðŸ’» Running locally\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ðŸ”§ Setting up environment for Google Colab...\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Clone the repository\n",
        "    print(\"\\nðŸ“¥ Step 1/4: Cloning repository...\")\n",
        "    if not os.path.exists('/content/Data-generation'):\n",
        "        subprocess.run(['git', 'clone', 'https://github.com/ayansh1729/Data-generation.git'], \n",
        "                      cwd='/content', check=True)\n",
        "        print(\"   âœ… Repository cloned\")\n",
        "    else:\n",
        "        print(\"   âœ… Repository already exists\")\n",
        "    \n",
        "    # Change to project directory\n",
        "    os.chdir('/content/Data-generation')\n",
        "    print(f\"   ðŸ“‚ Working directory: {os.getcwd()}\")\n",
        "    \n",
        "    # Install dependencies\n",
        "    print(\"\\nðŸ“¦ Step 2/4: Installing dependencies...\")\n",
        "    print(\"   (This may take 2-3 minutes...)\")\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-r', 'requirements.txt'], \n",
        "                   check=True)\n",
        "    print(\"   âœ… Dependencies installed\")\n",
        "    \n",
        "    # Install the package\n",
        "    print(\"\\nâš™ï¸  Step 3/4: Installing project as package...\")\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-e', '.'], \n",
        "                   check=True)\n",
        "    print(\"   âœ… Project installed\")\n",
        "    \n",
        "    # Add to Python path\n",
        "    sys.path.insert(0, '/content/Data-generation')\n",
        "    \n",
        "    # Verify installation\n",
        "    print(\"\\nðŸ§ª Step 4/4: Verifying installation...\")\n",
        "    try:\n",
        "        from src.models.diffusion import DDPM\n",
        "        from src.data.dataset import create_dataloader\n",
        "        from src.explainability.gradcam import GradCAMExplainer\n",
        "        print(\"   âœ… All modules imported successfully!\")\n",
        "    except ImportError as e:\n",
        "        print(f\"   âš ï¸  Import warning: {e}\")\n",
        "    \n",
        "    # Check GPU\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "        print(f\"\\nðŸŽ® GPU Available: {gpu_name}\")\n",
        "        print(f\"   Memory: {gpu_memory:.1f} GB\")\n",
        "    else:\n",
        "        print(\"\\nâš ï¸  No GPU detected. Training will be slower.\")\n",
        "        print(\"   ðŸ’¡ Enable GPU: Runtime â†’ Change runtime type â†’ GPU\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"âœ… Setup complete! You can now run the rest of the notebook.\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "else:\n",
        "    print(\"â„¹ï¸  Not in Colab - skipping Colab setup\")\n",
        "    print(\"   If running locally, make sure you've run: pip install -e .\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify all key packages are installed\n",
        "import sys\n",
        "\n",
        "def check_package(package_name, import_name=None):\n",
        "    \"\"\"Check if a package is installed\"\"\"\n",
        "    if import_name is None:\n",
        "        import_name = package_name\n",
        "    try:\n",
        "        module = __import__(import_name)\n",
        "        version = getattr(module, '__version__', 'unknown')\n",
        "        print(f\"âœ… {package_name:20s} - version {version}\")\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(f\"âŒ {package_name:20s} - NOT INSTALLED\")\n",
        "        return False\n",
        "\n",
        "print(\"ðŸ“‹ Checking installed packages...\\n\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "packages = [\n",
        "    ('torch', 'torch'),\n",
        "    ('torchvision', 'torchvision'),\n",
        "    ('numpy', 'numpy'),\n",
        "    ('matplotlib', 'matplotlib'),\n",
        "    ('seaborn', 'seaborn'),\n",
        "    ('pandas', 'pandas'),\n",
        "    ('sklearn', 'sklearn'),\n",
        "    ('diffusers', 'diffusers'),\n",
        "    ('tqdm', 'tqdm'),\n",
        "    ('PIL', 'PIL'),\n",
        "    ('yaml', 'yaml'),\n",
        "    ('omegaconf', 'omegaconf'),\n",
        "]\n",
        "\n",
        "all_installed = all(check_package(name, import_name) for name, import_name in packages)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if all_installed:\n",
        "    print(\"\\nðŸŽ‰ All core packages are installed!\")\n",
        "    print(\"âœ… You're ready to go!\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸  Some packages are missing. Please run:\")\n",
        "    print(\"   pip install -r requirements.txt\")\n",
        "\n",
        "# Check CUDA availability\n",
        "import torch\n",
        "print(f\"\\nðŸ”§ CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"   Running on CPU (slower but still works)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Framework components\n",
        "from src.models.diffusion import DDPM\n",
        "from src.models.unet import UNet\n",
        "from src.data.dataset import create_dataloader\n",
        "from src.training.losses import get_loss_function\n",
        "from src.training.scheduler import get_scheduler\n",
        "from src.explainability.gradcam import GradCAMExplainer, plot_gradcam_grid\n",
        "from src.explainability.attention_viz import AttentionVisualizer\n",
        "from src.explainability.diffusion_trace import DiffusionTracer\n",
        "from src.utils.visualization import plot_samples, plot_training_curves, plot_comparison\n",
        "from src.utils.config import load_config\n",
        "\n",
        "# Set style for better-looking plots\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "%matplotlib inline\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ðŸ”§ Using device: {device}\")\n",
        "print(f\"ðŸ PyTorch version: {torch.__version__}\")\n",
        "print(f\"âœ… Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataloader for CIFAR-10\n",
        "train_loader = create_dataloader(\n",
        "    dataset_name='cifar10',\n",
        "    batch_size=64,\n",
        "    num_workers=2,\n",
        "    image_size=32,\n",
        "    split='train'\n",
        ")\n",
        "\n",
        "print(f\"ðŸ“¦ Dataset loaded!\")\n",
        "print(f\"   - Number of batches: {len(train_loader)}\")\n",
        "print(f\"   - Batch size: {train_loader.batch_size}\")\n",
        "print(f\"   - Total images: ~{len(train_loader) * train_loader.batch_size:,}\")\n",
        "\n",
        "# Get a batch of real images\n",
        "real_batch = next(iter(train_loader))\n",
        "print(f\"\\nðŸ–¼ï¸  Batch shape: {real_batch.shape}\")\n",
        "print(f\"   - Range: [{real_batch.min():.2f}, {real_batch.max():.2f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize real samples\n",
        "fig = plot_samples(real_batch[:64], nrow=8, title=\"Real CIFAR-10 Images\", figsize=(14, 14))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model configuration\n",
        "model_config = {\n",
        "    'image_size': 32,\n",
        "    'channels': 3,\n",
        "    'timesteps': 1000,\n",
        "    'noise_schedule': 'cosine',\n",
        "    'dim': 64,\n",
        "    'dim_mults': (1, 2, 4, 8),\n",
        "    'num_res_blocks': 2,\n",
        "    'attention_resolutions': (16, 8),\n",
        "    'dropout': 0.1\n",
        "}\n",
        "\n",
        "# Create the diffusion model\n",
        "model = DDPM(**model_config).to(device)\n",
        "\n",
        "# Count parameters\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"ðŸ—ï¸  Model Architecture:\")\n",
        "print(f\"   - Total parameters: {num_params:,}\")\n",
        "print(f\"   - Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"   - Model size: ~{num_params * 4 / 1024 / 1024:.2f} MB\")\n",
        "print(f\"\\nâœ… Model created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "training_config = {\n",
        "    'num_epochs': 2,\n",
        "    'learning_rate': 2e-4,\n",
        "    'weight_decay': 0.0,\n",
        "    'gradient_clip': 1.0,\n",
        "}\n",
        "\n",
        "# Setup optimizer and scheduler\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=training_config['learning_rate'],\n",
        "    weight_decay=training_config['weight_decay']\n",
        ")\n",
        "\n",
        "scheduler = get_scheduler(\n",
        "    optimizer,\n",
        "    scheduler_type='cosine',\n",
        "    T_max=training_config['num_epochs'] * len(train_loader),\n",
        "    eta_min=1e-6\n",
        ")\n",
        "\n",
        "loss_fn = get_loss_function('mse')\n",
        "\n",
        "print(f\"âš™ï¸  Training Configuration:\")\n",
        "print(f\"   - Epochs: {training_config['num_epochs']}\")\n",
        "print(f\"   - Learning rate: {training_config['learning_rate']}\")\n",
        "print(f\"   - Optimizer: AdamW\")\n",
        "print(f\"   - Scheduler: Cosine Annealing\")\n",
        "print(f\"   - Gradient clip: {training_config['gradient_clip']}\")\n",
        "print(f\"\\nâœ… Training setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "model.train()\n",
        "losses = []\n",
        "best_loss = float('inf')\n",
        "\n",
        "for epoch in range(training_config['num_epochs']):\n",
        "    epoch_losses = []\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=f\"ðŸ“ˆ Epoch {epoch+1}/{training_config['num_epochs']}\")\n",
        "    for batch_idx, batch in enumerate(pbar):\n",
        "        batch = batch.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(batch)\n",
        "        loss = outputs['loss']\n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            model.parameters(),\n",
        "            training_config['gradient_clip']\n",
        "        )\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        epoch_losses.append(loss.item())\n",
        "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'lr': f\"{scheduler.get_last_lr()[0]:.2e}\"})\n",
        "        \n",
        "        # Early stop for demo (train on 100 batches only)\n",
        "        if batch_idx >= 100:\n",
        "            break\n",
        "    \n",
        "    avg_loss = np.mean(epoch_losses)\n",
        "    losses.append(avg_loss)\n",
        "    \n",
        "    print(f\"âœ¨ Epoch {epoch+1} complete - Average Loss: {avg_loss:.4f}\")\n",
        "    \n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        print(f\"   ðŸŽ¯ New best loss!\")\n",
        "\n",
        "print(f\"\\nðŸŽ‰ Training complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curve\n",
        "fig = plot_training_curves(losses, title=\"Training Loss Curve\", figsize=(10, 6))\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic samples\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print(\"ðŸŽ² Generating synthetic samples...\")\n",
        "    print(\"   (This takes ~1-2 minutes for 1000 denoising steps)\")\n",
        "    \n",
        "    generated_samples = model.sample(batch_size=64)\n",
        "    \n",
        "print(f\"\\nâœ… Generated {generated_samples.shape[0]} synthetic images!\")\n",
        "print(f\"   Shape: {generated_samples.shape}\")\n",
        "print(f\"   Range: [{generated_samples.min():.2f}, {generated_samples.max():.2f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize generated samples\n",
        "fig = plot_samples(\n",
        "    generated_samples,\n",
        "    nrow=8,\n",
        "    title=\"ðŸŽ¨ Generated Synthetic Images\",\n",
        "    figsize=(14, 14)\n",
        ")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare real vs generated\n",
        "fig = plot_comparison(\n",
        "    real_batch[:64],\n",
        "    generated_samples[:64],\n",
        "    nrow=8,\n",
        "    figsize=(14, 7)\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create GradCAM explainer\n",
        "explainer = GradCAMExplainer(model, target_layers=['mid_attn', 'mid_block1'])\n",
        "\n",
        "# Select samples to explain\n",
        "x_samples = real_batch[:4].to(device)\n",
        "t_timesteps = torch.tensor([250, 500, 750, 999]).to(device)\n",
        "\n",
        "print(\"ðŸ”¬ Computing GradCAM explanations...\")\n",
        "print(f\"   - Samples: {x_samples.shape[0]}\")\n",
        "print(f\"   - Timesteps: {t_timesteps.tolist()}\")\n",
        "print(f\"   - Target layers: {explainer.target_layers}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute GradCAM at different timesteps\n",
        "for idx, t in enumerate(t_timesteps):\n",
        "    t_batch = torch.full((x_samples.shape[0],), t.item(), device=device, dtype=torch.long)\n",
        "    \n",
        "    gradcams = explainer.compute_gradcam(x_samples, t_batch)\n",
        "    visualizations = explainer.visualize_gradcam(x_samples, t_batch, alpha=0.5)\n",
        "    \n",
        "    print(f\"\\nðŸ“Š Timestep t={t.item()}:\")\n",
        "    print(f\"   - Computed GradCAM for {len(gradcams)} layers\")\n",
        "    \n",
        "    # Visualize\n",
        "    for layer_name, viz in list(visualizations.items())[:1]:  # Show first layer\n",
        "        fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
        "        for i in range(4):\n",
        "            axes[i].imshow(viz[i])\n",
        "            axes[i].axis('off')\n",
        "            axes[i].set_title(f'Sample {i+1}', fontsize=10)\n",
        "        \n",
        "        plt.suptitle(f'GradCAM at t={t.item()} - Layer: {layer_name}', fontsize=14, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    if idx >= 1:  # Show only 2 timesteps for demo\n",
        "        break\n",
        "\n",
        "# Cleanup\n",
        "explainer.remove_hooks()\n",
        "print(\"\\nâœ… GradCAM analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
